# DeepLabCut (DLC) Workshop

This repository provides a short practical introduction to **DeepLabCut (DLC)** ‚Äî a deep learning toolbox for **markerless pose estimation**. DLC enables researchers to track animal and human movement from videos by extracting **x,y coordinates of defined keypoints** (e.g., nose, tail, paws).

---

## üöÄ Workshop Overview

In this workshop you will:

- Learn the basics of DLC and markerless pose estimation.  
- Practice **labelling behaviour videos** with DLC‚Äôs GUI.  
- Run **Google Colab notebooks** for training and analysing models.  
- Gain experience in **evaluating and refining models**.  

DLC can be used in two ways:
- **Google Colab notebooks** (for training and analysis without local installation).  
- **DLC GUI** (for manual labelling and project management, requires installation).  

---

## üõ†Ô∏è Getting Started

- **Colab Training (Recommended):**  
  - Open demo notebooks for single- or multi-animal tracking:  
    - [Single mouse demo](https://colab.research.google.com/github/DeepLabCut/DeepLabCut/blob/master/examples/COLAB/COLAB_DEMO_mouse_openfield.ipynb)  
    - [Three mice demo](https://colab.research.google.com/github/DeepLabCut/DeepLabCut/blob/master/examples/COLAB/COLAB_DEMO_3mice_openfield.ipynb)  
  - Requires a Google account. Enable GPU for faster performance.  
  - Save outputs locally before ending a session.  

- **GUI for Labelling (Local Use):**  
  - Install DLC following the [Beginner‚Äôs Guide](https://deeplabcut.github.io/DeepLabCut/docs/beginner-guides/beginners-guide.html).  
  - Video tutorial: [How to use the GUI](https://www.youtube.com/watch?v=ofFx0vTMSxE).  
  - GUI allows creating projects, extracting frames, labelling keypoints, training models, and analysing videos.  

---

## üìÇ Resources & Downloads

- üì¶ Workshop materials on GitHub: [Insert GitHub Link Here]  
- üì• Download package via WeTransfer: [Insert WeTransfer Link Here]  

---

## üí° Designing Your Own Project

To set up your own DLC project:
1. Define the **behaviour of interest** (e.g., walking, grooming).  
2. Identify the **keypoints** to track (e.g., paws, joints, nose).  
3. Label frames, train your model, and iteratively refine until performance is satisfactory.  

---

## üìö Additional Resources

- [Beginner‚Äôs Guide to DLC](https://deeplabcut.github.io/DeepLabCut/docs/beginner-guides/beginners-guide.html)  
- [DLC GUI Tutorial Video](https://www.youtube.com/watch?v=ofFx0vTMSxE)  
- [Google Colab Demos](https://github.com/DeepLabCut/DeepLabCut/tree/master/examples/COLAB)  

---
