
LINK TO PDF OF WORKBOOK
https://we.tl/t-Cly5RfZOiu


# DeepLabCut (DLC) Workshop

This repository provides a short practical introduction to **DeepLabCut (DLC)** ‚Äî a deep learning toolbox for **markerless pose estimation**. DLC enables researchers to track animal and human movement from videos by extracting **x,y coordinates of defined keypoints** (e.g., nose, tail, paws).

---

## üöÄ Workshop Overview

In this workshop you will:

- Learn the basics of DLC and markerless pose estimation.  
- Practice **labelling behaviour videos** with DLC‚Äôs GUI.  
- Run **Google Colab notebooks** for training and analysing models.  
- Gain experience in **evaluating and refining models**.  

DLC can be used in two ways:
- **Google Colab notebooks** (for training and analysis without local installation).  
- **DLC GUI** (for manual labelling and project management, requires installation).  

---

## üõ†Ô∏è Getting Started

- **Colab Training (Recommended):**  
  - Open demo notebooks for single- or multi-animal tracking:  
    - Single animal tracking ‚Äì please download the folder with data and script from [Wetransfer](https://we.tl/t-wTCBfrtxx2) or on [Github](https://github.com/AnnaStuckert/DeepLabCutWorkshupAlmer-a2025)
    - Run the script DLC_training.ipynb for training a DLC project
    - Run the script DEMO_Superanimals.ipynb for testing Superanimal models
  - Requires a Google account. Enable GPU for faster performance.  


- **GUI for Labelling (Local Use):**  
  - Install DLC following the [Beginner‚Äôs Guide](https://deeplabcut.github.io/DeepLabCut/docs/beginner-guides/beginners-guide.html).  
  - Video tutorial: [How to use the GUI](https://www.youtube.com/watch?v=ofFx0vTMSxE).  
  - GUI allows creating projects, extracting frames, labelling keypoints, training models, and analysing videos.  

---

## üìÇ Resources & Downloads

- üì¶ Workshop materials on GitHub: [Github](https://github.com/AnnaStuckert/DeepLabCutWorkshupAlmer-a2025)  
- üì• Download package via WeTransfer: [Wetransfer](https://we.tl/t-ynGT0lGW8I) active for 3 days

---

## üí° Designing Your Own Project

To set up your own DLC project:
1. Define the **behaviour of interest** (e.g., walking, grooming).  
2. Identify the **keypoints** to track (e.g., paws, joints, nose).  
3. Label frames, train your model, and iteratively refine until performance is satisfactory.  

---

## üìö Additional Resources

- [Beginner‚Äôs Guide to DLC](https://deeplabcut.github.io/DeepLabCut/docs/beginner-guides/beginners-guide.html)  
- [DLC GUI Tutorial Video](https://www.youtube.com/watch?v=ofFx0vTMSxE)  
- [Google Colab Demos](https://github.com/DeepLabCut/DeepLabCut/tree/master/examples/COLAB)  


Documentation and forums
- [Cajal DLC course book](https://alexemg.github.io/DLC-Cajal-Course/content/Day1_Overview.html)
- [DLC Documentation](https://deeplabcut.github.io/DeepLabCut/README.html)
- [DLC forum (get assistance)](https://forum.image.sc/tag/deeplabcut)
- [DLC video tutorials](https://www.youtube.com/@deeplabcut7702)

Papers
- [Using DeepLabCut for 3D markerless pose estimation across species and behaviors](https://www.nature.com/articles/s41596-019-0176-0)
- [Multi-animal pose estimation](https://www.nature.com/articles/s41592-022-01443-0)
- [SuperAnimal pretrained pose estimation models](https://www.nature.com/articles/s41467-024-48792-2)
- [Keypoint-MoSeq](https://www.nature.com/articles/s41592-024-02318-2)

---
